{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake News Classication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the two datasets:\n",
    "1. ABC news article titles for 14 years\n",
    "2. The Examiner news articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data setup and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "data_set_loc = '/Users/koo01a/Desktop/fake_news'\n",
    "\n",
    "# Read in white wine data \n",
    "# https://www.kaggle.com/therohk/million-headlines\n",
    "abc = pandas.DataFrame(pandas.read_csv(data_set_loc+\"/abcnews-date-text.csv\", sep=','))\n",
    "\n",
    "# Read in red wine data \n",
    "# https://www.kaggle.com/therohk/examine-the-examiner\n",
    "examiner = pandas.DataFrame(pandas.read_csv(data_set_loc+\"/examiner-date-text.csv\", sep=','))\n",
    "\n",
    "print(abc.info())\n",
    "print(examiner.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(abc.head())\n",
    "from lolviz import *\n",
    "g = listviz(['hi','mom',{3,4},{\"parrt\":\"user\"}])\n",
    "g.render(view=True) # render graphviz.files.Source object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign examiner as fake (fake=1) and abs as not fake (fake=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add `type` column to `red` with value 1\n",
    "examiner['fake'] = 1\n",
    "\n",
    "# Add `type` column to `white` with value 0\n",
    "abc['fake'] = 0\n",
    "\n",
    "# Append `white` to `red`\n",
    "articles = pandas.concat([examiner,abc]).sort_index().reset_index(drop=True)[:100000]\n",
    "#articles = examiner.append(abc, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(articles.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles['headline_text'] = [str(headline) for headline in articles['headline_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "MAX_WORDS=30000\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts(articles['headline_text'])\n",
    "\n",
    "X = tokenizer.texts_to_matrix(articles['headline_text'], mode='binary')\n",
    "y = y=np.ravel(articles['fake'])\n",
    "\n",
    "#tokenizer.texts_to_sequences(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokenizer.word_index)\n",
    "tokenizer.texts_to_matrix([\"to in the\", \"the brisbane winter\",\"surf\"])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(500, activation=\"relu\", input_dim=len(tokenizer.word_index) + 1))\n",
    "model.add(Dense(80, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=5, validation_split=.5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('fake-news-classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try some classification of arbitrary text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"10 best holiday destinations.\"\n",
    "input_vector = tokenizer.texts_to_matrix([input_text], mode='binary')\n",
    "prob_fake = model.predict(input_vector)[0][0]\n",
    "\n",
    "print(\"Classifier thinks this is%s fake (p=%s).\" % (\" not\" if prob_fake < 0.5 else \"\", round(prob_fake,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorrect classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles['predictions'] = predictions\n",
    "errors = [(articles['headline_text'][i], articles['fake'][i], articles['predictions'][i]) for i in range(0,len(articles)) if articles['fake'][i] != articles['predictions'][i]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X, y,verbose=1)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
